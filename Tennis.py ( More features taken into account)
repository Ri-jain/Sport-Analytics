# =========================
# Utilities (NEW)
# =========================
import unicodedata, re, warnings
warnings.filterwarnings("ignore")

def norm(s):
    """Normalize names/strings (strip accents, collapse spaces)."""
    if pd.isna(s): return s
    s = str(s)
    s = unicodedata.normalize("NFKD", s)
    s = "".join(ch for ch in s if not unicodedata.combining(ch))
    s = re.sub(r"\s+", " ", s).strip()
    return s

def parse_date_col(series):
    """Robust parse for tourney_date across mixed formats."""
    s_str = series.astype(str)
    dt1 = pd.to_datetime(s_str, format="%Y%m%d", errors="coerce")
    dt2 = pd.to_datetime(s_str, errors="coerce")
    return dt1.fillna(dt2)

def is_grand_slam(level, name):
    return (str(level) == "G") or ("Grand Slam" in str(name)) or ("US Open" in str(name))

def safe_div(num, den, default=0.0):
    return float(num) / float(den) if den and den != 0 else float(default)

# =========================
# Serve/Return Aggregates (NEW)
# =========================
def aggregate_srvret(matches, decay_rate=0.95):
    # ... builds decayed serve/return stats per player
    return finalize(agg_all), finalize(agg_hard)

srv_all, srv_hard = aggregate_srvret(df_all)

# =========================
# Head-to-Head (NEW)
# =========================
def build_h2h(matches):
    h2h = defaultdict(lambda: defaultdict(int))
    for _, m in matches.iterrows():
        w, l = m["winner_name"], m["loser_name"]
        h2h[w][l] += 1
    return h2h

H2H = build_h2h(df_all)

# =========================
# Feature Engineering (EXTRA FEATURES)
# =========================
def match_feature_row(w, l, m, use_hard=True):
    feat = {
        "elo_diff": elo_overall[w] - elo_overall[l],
        "elo_hard_diff": elo_hard[w] - elo_hard[l],
        "elo_usopen_diff": elo_usopen[w] - elo_usopen[l],
        "form_diff": pstats[w]['recent_form'] - pstats[l]['recent_form'],
        "hard_wr_diff": pstats[w]['hard_win_rate'] - pstats[l]['hard_win_rate'],
        "gs_wr_diff": pstats[w]['gs_win_rate'] - pstats[l]['gs_win_rate'],
        "matches_diff": np.log1p(pstats[w]['total_matches']) - np.log1p(pstats[l]['total_matches']),
        "age_diff": m.get("winner_age",25) - m.get("loser_age",25),
        "best_of_5": 1 if m.get("best_of",3)==5 else 0,
        "is_hard": 1 if str(m.get("surface","")).lower()=="hard" else 0,
        "h2h_diff": H2H[w][l] - H2H[l][w],   # NEW
        "srv_aces_pg_diff": srv_hard[w]['srv_aces_pg'] - srv_hard[l]['srv_aces_pg'],
        "srv_df_pg_diff":   srv_hard[w]['srv_df_pg'] - srv_hard[l]['srv_df_pg'],
        "srv_1stin_diff":   srv_hard[w]['srv_1stin'] - srv_hard[l]['srv_1stin'],
        "srv_1stwon_diff":  srv_hard[w]['srv_1stwon'] - srv_hard[l]['srv_1stwon'],
        "srv_2ndwon_diff":  srv_hard[w]['srv_2ndwon'] - srv_hard[l]['srv_2ndwon'],
        "srv_bpsave_diff":  srv_hard[w]['srv_bpsave'] - srv_hard[l]['srv_bpsave'],
    }
    return feat

FEATURE_ORDER = [
    "elo_diff","elo_hard_diff","elo_usopen_diff",
    "form_diff","hard_wr_diff","gs_wr_diff",
    "matches_diff","age_diff","best_of_5","is_hard","h2h_diff",
    "srv_aces_pg_diff","srv_df_pg_diff","srv_1stin_diff",
    "srv_1stwon_diff","srv_2ndwon_diff","srv_bpsave_diff"
]

# =========================
# Models & Calibration (NEW)
# =========================
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import accuracy_score, log_loss, brier_score_loss

scaler = StandardScaler()
X_train_s = scaler.fit_transform(X_train)
X_test_s  = scaler.transform(X_test)

base_lr = LogisticRegression(max_iter=1000, random_state=42)
lr = CalibratedClassifierCV(base_lr, method="isotonic", cv=3).fit(X_train_s, y_train)

base_hgb = HistGradientBoostingClassifier(max_iter=400, learning_rate=0.07, random_state=42)
hgb = CalibratedClassifierCV(base_hgb, method="isotonic", cv=3).fit(X_train, y_train)

# Ensemble blending
p_blend = 0.4*lr.predict_proba(X_test_s)[:,1] + 0.4*hgb.predict_proba(X_test)[:,1] + 0.2*p_elo

# =========================
# Simulation Noise (UPDATED)
# =========================
def match_prob(p1, p2):
    p_lr  = lr.predict_proba(scaler.transform(feat))[:,1]
    p_hgb = hgb.predict_proba(feat)[:,1]
    p_elo = 1.0/(1.0+10.0**(-(elo_diff)/400.0))
    p = 0.4*p_lr + 0.4*p_hgb + 0.2*p_elo
    eps = np.random.normal(0.0, 0.03)         # NEW zero-mean noise
    return float(np.clip(p + eps, 0.02, 0.98))
